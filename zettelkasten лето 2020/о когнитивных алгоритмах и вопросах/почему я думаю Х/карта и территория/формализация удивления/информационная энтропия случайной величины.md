# информационная энтропия случайной величины
Информационная энтропия случайной величины - это математическое ожидание информации (удивления), которое мы от нее получим.

Для дискретного случая 

H = - \\sum\_i \\mathbb{P} (\\ksi = x\_i) \\log \\mathbb{P} (\\ksi = x\_i)

связано с [формализация удивления](%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%83%D0%B4%D0%B8%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F)