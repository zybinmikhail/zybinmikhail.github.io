# практика ML, гиперпараметры
На практике надо еще предварительно обрабатывать данные и заниматься подбором гиперпараметров.

Часть параметров модели, по которым модель является дифференцируемой функцией, можно подбирать с помощью численных методов градиентной оптимизации (как это делается, к примеру, в глубоком обучении с помозью метода обратного распространения ошибки).

Иногда оптимальные параметры можно подобрать аналитически, как в случае линейной регрессии.

Другая часть параметров модели называется гиперпараметрами и подбирается на основе кросс-валидации, эвристик, случайности и интуиции. Примеры: число слоев нейросети, число нейронов с слоях, функции активации в слоях, максимальная глубина решающего дерева, критерий ветвления решающего дерева, число решающих деревьев в ансамблевой модели.

[глубокое обучение](%D0%B3%D0%BB%D1%83%D0%B1%D0%BE%D0%BA%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5)

[машинное обучение](%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5)

[практика важна](%D0%BF%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0%20%D0%B2%D0%B0%D0%B6%D0%BD%D0%B0)