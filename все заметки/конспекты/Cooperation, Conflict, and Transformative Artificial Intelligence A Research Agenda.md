КОнспект [этого](https://longtermrisk.org/research-agenda)

CLR в числе прочего фокусируется на решении вопроса, как не допустить каткстрофических событий в результате взаимодействия TAI (Transformative AI). TAI может сыгтать ключевую роль в судьбе нашей цивилизации.
TAI - AI, который приводит к радикальому изменению, сравнимому или превохсодящему аграрную и индустриальную революцию.
AI можно себе мыслить как единого агента или как людей, снабженных широким спектром слабых ИИ. Хорошая идея - уменьшать риски от "проваленной" кооперации уже сейчас, хотя очень непонятно, когда такие системы смогут появиться.
Взаимодействие между мощными акторами и особенности машинного интеллекта могут сильно изменить
1. Возможность делать достоверные коммитменты
2. Изменять себя
3. Моделировать других агентов

# 1.1 Провал кооперации: модели и примеры
Взаимный обман в социальной дилемме. Социальная дилемма - ситуация, когда всем лучше если все кооперируются, причем каждому в отдельности лучше обмануть. Пример - дилемма заключенного, гонка вооружений, трагедия общин.
Некоторые ситуации не моделируются так просто, потому что есть неполная информация.

Возможен вариант, когда агенты идут на войну из-за неразделимых ресурсов. В данном случае можно провести симуляцию войны на компьютере, и ресурс получает тот, кто выигрывает там.

TAI могут не быть хорошо моделируемыми ка рациональные агенты, если они, например, содержат человека или натренированы эволюционным методом.

# 5. Современные архитектуры ИИ
Может быть, TAI будут совсем отличающимися от существующих ИИ-систем. Однако может быть ресерч провалов кооперации в текущих ИИ-системах может оказаться полезен.
## 5.1 Учимся решать социальные дилеммы
В глубоком RL кто-то что-то пытался делать.

## 5.2 Мультиагентное обучение
## 5.3 Теория принятия решений
# 6. Humans in the loop
##
# 7. Основы рациональной агентности
CDT vs EDT
FDT